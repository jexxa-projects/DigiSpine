# Important note: For using this file, you must adjust some settings such as IP addresses to your environment.
# These settings are highlighted by a TODO comment

#replace the following hosts
# 'kafka-broker' with the name or IP of your kafka-broker

version: '3.8'
services:
  kafka1:
    image: confluentinc/cp-kafka
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      #Define the name for Broker and controller and protocols
      KAFKA_INTER_BROKER_LISTENER_NAME: 'BROKER'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT

      #Define the ports used for broker, controller and external
      KAFKA_LISTENERS: BROKER://kafka1:29092,CONTROLLER://kafka1:29093,EXTERNAL://:9092
      # TODO: Adjust advertised IP address from 'kafka-broker:9092' to hostname or ip address of running system
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka1:29092,EXTERNAL://kafka-broker:9092

      # Configure replication factors for autocreate topics, consumer offsets, log-topic and re-balance delay
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      # Following parameters are required to run Kafka in Kraft mode (without Zookeeper)
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      # TODO: Generate ONE kafka-ID using ./bin/kafka-storage.sh random-uuid and set it to all instances
      CLUSTER_ID: 'aiWo7IWazngRchmPES6q5A=='

      # Required to avoid log spamming from MetdataLoader
      KAFKA_LOG4J_LOGGERS: 'org.apache.kafka.image.loader.MetadataLoader=WARN'

      # Required to enable Confluent Schema Registry
      KAFKA_CONFLUENT_SUPPORT_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schemaregistry:8085"
      KAFKA_CONFLUENT_VALUE_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_KEY_SCHEMA_VALIDATION: "true"

    volumes:
      - kafka1-data:/var/lib/kafka/data


    deploy:
      placement:
        constraints:
          # TODO: To ensure that kafka instances are not placed on the same VM, you should define different constraints such as manager or worker to ensure that at least two instances run on different VMs
          - "node.role == manager"

  kafka2:
    image: confluentinc/cp-kafka
    hostname: kafka2
    ports:
      - "9093:9092"
    environment:

      #Define the name for Broker and controller and protocols
      KAFKA_INTER_BROKER_LISTENER_NAME: 'BROKER'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT

      #Define the ports used for broker, controller and external
      KAFKA_LISTENERS: BROKER://kafka2:29092,CONTROLLER://kafka2:29093,EXTERNAL://:9092
      # TODO: Adjust advertised IP address from 'kafka-broker:9093' to hostname or ip address of running system
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka2:29092,EXTERNAL://kafka-broker:9093

      # Configure replication factors for autocreate topics, consumer offsets,log-topic and re-balance delay
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      # Following parameters are required to run Kafka in Kraft mode (without Zookeeper)
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 2
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      # TODO: Generate ONE kafka-ID using ./bin/kafka-storage.sh random-uuid and set it to all instances
      CLUSTER_ID: 'aiWo7IWazngRchmPES6q5A=='

      # Required to avoid log spamming from MetdataLoader
      KAFKA_LOG4J_LOGGERS: 'org.apache.kafka.image.loader.MetadataLoader=WARN'

      # Required to enable Confluent Schema Registry
      KAFKA_CONFLUENT_SUPPORT_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schemaregistry:8085"
      KAFKA_CONFLUENT_VALUE_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_KEY_SCHEMA_VALIDATION: "true"

    volumes:
      - kafka2-data:/var/lib/kafka/data

    deploy:
      placement:
        constraints:
          # TODO: To ensure that kafka instances are not placed on the same VM, you should define different constraints such as manager or worker to ensure that at least two instances run on different VMs
          - "node.role == manager"

  kafka3:
    image: confluentinc/cp-kafka
    hostname: kafka3
    ports:
      - "9094:9092"
    environment:

      # Define the name for Broker and controller and protocols
      KAFKA_INTER_BROKER_LISTENER_NAME: 'BROKER'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Define the ports used for broker, controller and external
      KAFKA_LISTENERS: BROKER://kafka3:29092,CONTROLLER://kafka3:29093,EXTERNAL://:9092
      # TODO: Adjust advertised IP address from 'kafka-broker:9094' to hostname or ip address of running system
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka3:29092,EXTERNAL://kafka-broker:9094

      # Configure replication factors for autocreate topics, consumer offsets,log-topic and re-balance delay
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      # Following parameters are required to run Kafka in Kraft mode (without Zookeeper)
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 3
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      # TODO: Generate ONE kafka-ID using ./bin/kafka-storage.sh random-uuid and set it to all instances
      CLUSTER_ID: 'aiWo7IWazngRchmPES6q5A=='

      # Required to avoid log spamming from MetdataLoader
      KAFKA_LOG4J_LOGGERS: 'org.apache.kafka.image.loader.MetadataLoader=WARN'

      # Required to enable Confluent Schema Registry
      KAFKA_CONFLUENT_SUPPORT_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schemaregistry:8085"
      KAFKA_CONFLUENT_VALUE_SCHEMA_VALIDATION: "true"
      KAFKA_CONFLUENT_KEY_SCHEMA_VALIDATION: "true"

    volumes:
      - kafka3-data:/var/lib/kafka/data

    deploy:
      placement:
        constraints:
          # TODO: To ensure that kafka instances are not placed on the same VM, you should define different constraints such as manager or worker to ensure that at least two instances run on different VMs
          - "node.role == manager"

  schemaregistry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schemaregistry
    ports:
      - 18085:8085
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:29092,PLAINTEXT://kafka2:29092,PLAINTEXT://kafka3:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8085
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "9080:8080"

    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: digispine-production
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29092,kafka2:29092,kafka3:29092
      # Automatically register schemaregistry and ksqldbServer in kafka-ui
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: "http://schemaregistry:8085"
      KAFKA_CLUSTERS_0_KSQLDBSERVER: http://ksqldbServer:8088

    healthcheck:
      test: ["CMD-SHELL", "wget -nv -t1 --spider 'http://localhost:8080'"]
      interval: 10s
      timeout: 10s
      retries: 3

  ksqldbServer:
    image: confluentinc/cp-ksqldb-server:latest
    hostname: ksqldbServer
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29092,kafka3:29092
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schemaregistry:8085
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"

  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:latest
    entrypoint: /bin/sh
    tty: true

volumes:
  kafka1-data:
  kafka2-data:
  kafka3-data:
